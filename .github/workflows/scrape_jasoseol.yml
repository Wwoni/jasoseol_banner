name: Scrape Jasoseol Banners

on:
  workflow_dispatch: {}
  schedule:
    # 매주 월요일 01:00 UTC 실행 = 한국시간(KST, UTC+9) 오전(10:00)
    - cron: "0 1 * * 1"

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # (1) 서비스계정 JSON 파일 생성
      - name: Write service account JSON
        shell: bash
        env:
          GDRIVE_SA_JSON: ${{ secrets.GDRIVE_SA_JSON }}  # <-- 리포 Secrets에 저장한 JSON 원문
        run: |
          printf '%s' "$GDRIVE_SA_JSON" > gdrive_sa.json

      # (2) 크롤링 + 드라이브 업로드 실행
      - name: Run crawler & upload
        env:
          # 필수: 공유드라이브 내 '대상 폴더 ID'
          GDRIVE_FOLDER_ID: ${{ secrets.GDRIVE_FOLDER_ID }}
          # 선택: 공유드라이브 ID(검색 최적화)
          GDRIVE_DRIVE_ID: ${{ secrets.GDRIVE_DRIVE_ID }}
          # 선택: 서비스계정 JSON 경로(기본 gdrive_sa.json)
          GDRIVE_SA_JSON_PATH: gdrive_sa.json
        run: |
          python jasoseol_banner.py

      # (옵션) 결과물/디버그 아티팩트 업로드
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: jasoseol_banner_outputs
          path: |
            jasoseol_banner.csv
            last_run.txt
            debug_home.html
            debug_next_data.json
          if-no-files-found: warn